import OpenAI from 'openai'
import { collection, getDocs } from 'firebase/firestore'
import { db } from '@/app/firebase'
import { NextRequest, NextResponse } from 'next/server'

interface Post {
  content: string
  createdAt: string
  mm: number
}

const openai = new OpenAI({
  apiKey: process.env.NEXT_OPENAI_API_KEY,
})

function cosineSimilarity(vecA: number[], vecB: number[]) {
  const dot = vecA.reduce((sum, a, i) => sum + a * vecB[i], 0)
  const magA = Math.sqrt(vecA.reduce((sum, a) => sum + a * a, 0))
  const magB = Math.sqrt(vecB.reduce((sum, b) => b * b, 0))
  return dot / (magA * magB)
}

async function getEmbedding(text: string) {
  const response = await openai.embeddings.create({
    model: 'text-embedding-3-large',
    input: text,
  })
  return response.data[0].embedding
}

async function fetchCommunityPosts(): Promise<Post[]> {
  const postSnapshot = await getDocs(collection(db, 'posts'))
  return postSnapshot.docs.map(doc => doc.data() as Post)
}

export async function GET(_req: NextRequest) {
  try {
    console.log('ğŸ”¥ ìš”ì•½ API ì‹œì‘')

    const posts = await fetchCommunityPosts()
    console.log('ğŸ“¦ ë¶ˆëŸ¬ì˜¨ ê¸€ ê°œìˆ˜:', posts.length)

    const defaultQuery = 'ì¸ì²œ ì»¤ë®¤ë‹ˆí‹° íŠ¸ë Œë“œ ë¶„ì„'
    const queryEmbedding = await getEmbedding(defaultQuery)
    console.log('ğŸ”¢ ì¿¼ë¦¬ ì„ë² ë”© ì™„ë£Œ')

    const postsWithEmbeddings = await Promise.all(
      posts.map(async post => {
        console.log('ğŸ“ ì²˜ë¦¬ ì¤‘ ê¸€:', post.content.slice(0, 20))
        return {
          ...post,
          embedding: await getEmbedding(post.content),
        }
      })
    )
    console.log('ğŸ“Š ëª¨ë“  ì„ë² ë”© ì™„ë£Œ')

    const topPosts = postsWithEmbeddings
      .map(post => ({
        ...post,
        score: cosineSimilarity(queryEmbedding, post.embedding),
      }))
      .sort((a, b) => b.score - a.score)
      .slice(0, 5)

    const context = topPosts.map(p => `- ${p.content}`).join('\n')

    const prompt = `ë„ˆëŠ” ì§€ì—­ ì»¤ë®¤ë‹ˆí‹°ì˜ ê¸€ë“¤ì„ ë¶„ì„í•´ì„œ íŠ¸ë Œë“œë¥¼ ìš”ì•½í•˜ëŠ” AIì•¼.
ì•„ë˜ëŠ” ì§€ë‚œ ì¼ì£¼ì¼ ë™ì•ˆ ì¸ì²œ ì»¤ë®¤ë‹ˆí‹°ì— ì˜¬ë¼ì˜¨ ê¸€ ëª©ë¡ì´ì•¼:

${context}

ìœ„ ë‚´ìš©ì„ ë°”íƒ•ìœ¼ë¡œ ì•„ë˜ 4ê°€ì§€ ì¹´í…Œê³ ë¦¬ë¡œ ë‚˜ëˆ ì„œ ìš”ì•½í•´ì¤˜:
1. ğŸ¯ ì¼ìƒ / ì¡ë‹´
2. ğŸ§© ì •ë³´ / íŒ
3. ğŸš§ ë¶ˆí¸ / ê±´ì˜
4. ğŸ  ìƒí™œ / í™˜ê²½

ê° ì¹´í…Œê³ ë¦¬ë§ˆë‹¤ 1~2ë¬¸ì¥ìœ¼ë¡œ í•µì‹¬ì„ ì •ë¦¬í•´ì¤˜.`

    console.log('ğŸ§  GPTì— ì „ë‹¬í•  í”„ë¡¬í”„íŠ¸:', prompt)

    const completion = await openai.chat.completions.create({
      model: 'gpt-3.5-turbo',
      messages: [
        { role: 'system', content: 'You are a helpful assistant that summarizes community trends.' },
        { role: 'user', content: prompt },
      ],
    })

    const summary = completion.choices[0].message.content
    console.log('âœ… ìš”ì•½ ì™„ë£Œ:', summary)

    return NextResponse.json({ summary })
  } catch (error) {
    console.error('âŒ ìš”ì•½ API ì—ëŸ¬:', error)
    return NextResponse.json({ error: 'Internal Server Error' }, { status: 500 })
  }
}